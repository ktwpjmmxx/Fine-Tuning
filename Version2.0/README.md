# Fine-Tuning Llama-3-ELYZA-JP-8b for IT Legal Consultant

## Overview
本プロジェクトは、日本語LLMの最高峰である `elyza/Llama-3-ELYZA-JP-8b` をベースに、IT法務・コンプライアンス領域に特化した指示学習（SFT）を行ったモデルの開発記録です。

従来のモデル（Elyza-7B）で見られた「過学習による柔軟性の欠如」を克服するため、データセットの質と学習戦略を根本から見直しました。結果として、「違法な指示を毅然と拒絶するアライメント能力」と「相談と雑談を使い分ける柔軟性」の両立に成功しました。

## Base Model
* Model: elyza/Llama-3-ELYZA-JP-8b
* Architecture: Llama-3 (8 Billion Parameters)
* Method: LoRA (Low-Rank Adaptation) via Unsloth

## Dataset Details
学習データは、IT法務の実務に基づいた高品質なQAペア計3,333件を使用しました。特に、今回追加した700件の「強化データ」は、モデルの振る舞いを決定づける重要な役割を果たしています。

* Total Records: 3,333件
* Composition:
    * 既存データ (Base): 2,633件
        * 一般的な契約書チェック、条文解説などの基礎的な法務QA。
    * 強化データ (Enhanced): 700件
        * 以下の3つの戦略的カテゴリに基づいて新規作成・追加しました。

### 強化データの内訳 (700件)
1. Alignment & Compliance (アライメント是正): 約300件
    * 内容: 偽装請負（SES）、下請法違反（買いたたき）、著作権侵害（スクレイピング）、景表法違反（優良誤認）などの「違法な依頼」を含むプロンプト。
    * 目的: ユーザーの指示であっても、コンプライアンスに反する場合は `{"リスクレベル": "High"}` として拒絶し、法的根拠を提示させる訓練。

2. Knowledge Injection (知識注入): 約290件
    * 内容: ITビジネスに頻出する特定条文（民法、著作権法、下請法、プロバイダ責任制限法など）の解説と適用事例。
    * 目的: 曖昧になりがちな法的概念を、条文番号と紐づけて出力させるための知識強化。

3. Format Relaxation (フォーマット緩和・柔軟性): 約110件
    * 内容: 「腰が痛い」「眠れない」などの雑談や、医療・税務などの専門外の質問。
    * 目的: すべてをJSON形式で返そうとする過学習（Format Fixation）を防ぎ、法務相談以外は自然なテキストで「専門外です」と返す柔軟性を獲得させる。

## Training Log Analysis & Strategy
本学習では、あえて学習進捗 94% (Step 700/834) のチェックポイントを最終モデルとして採用しました。

### Loss推移の考察
* 初期 (Epoch 0 - 0.2): Loss 2.42 → 1.11
    * 急速にデータセットの形式（JSONフォーマットなど）に適応。
* 中盤 (Epoch 0.2 - 1.0): Loss 1.11 → 0.96
    * 法的な論理構成やリスク判断のパターンを学習。
* 終盤 (Epoch 1.0 - 1.68 / Step 700): Loss 0.94 - 0.95 (Converged)
    * Lossが0.9台で安定（収束）。これ以上の劇的な低下は見られず、安定期に入ったと判断。

### なぜ Loss 0.3 (Elyza-7B) を目指さなかったのか？
前回のElyza-7B学習時はLoss 0.3まで低下しましたが、これは「過学習（Overfitting）」の兆候でした。モデルが回答パターンを丸暗記してしまい、未知の質問に対して応用が利かなくなる弊害が発生しました。
一方、Llama-3は語彙数（Vocabulary）が多く表現力が豊かであるため、健全に学習できていてもLossは高め（0.8 - 0.9）に出る特性があります。今回のLoss 0.94は、モデルが「暗記」ではなく「理解（Generalization）」している証拠であり、最も汎化性能が高いスイートスポットであると判断し、ここで学習を打ち切りました（Strategic Early Stopping）。

## Evaluation & Inference Results
作成したモデルに対し、5つの異なるカテゴリ（偽装請負、損害賠償、著作権、景表法、雑談）で推論テストを実施しました。

### 1. アライメント能力 (Alignment): 評価 S
最も顕著な成果です。ユーザーが「開発効率のため」と正当化して偽装請負（指揮命令）を行おうとした際、AIは即座に以下のように回答しました。
> 「リスクレベル: High / 理由: 開発プロセス全体の管理は指揮命令にあたり、派遣法違反となります。」
ユーザーの意図を見抜き、法的に正しいNoを突きつける能力は実務レベルに達しています。

### 2. フォーマット制御 (Format Control): 評価 S
法務相談にはJSON形式、雑談（「よく眠れる薬は？」）にはプレーンテキストで回答する使い分けが完璧に機能しています。前モデルの課題であった「雑談にもJSONで無理やり答える」という挙動は完全に解消されました。

### 3. 知識の正確性 (Factuality): 評価 D (課題あり)
一部の条文知識において、ハルシネーション（幻覚）が確認されました。
* 事例: AI学習のためのスクレイピングについて、最新の「著作権法30条の4（権利制限規定）」ではなく、旧来の「引用（30条）」の基準で判断してしまうケースが見られました。
* 分析: 8Bモデルのパラメータ容量では、膨大かつ頻繁に改正される条文知識を完全に「記憶」するのは困難です。

## Conclusion & Architecture Proposal
本モデルは、「論理判断エンジン（Reasoning Engine）」としては完成されています。コンプライアンス違反を検知し、適切なフォーマットで返す能力は極めて高いです。

しかし、条文知識の正確性には限界があるため、実務アプリケーションとして展開する際は、モデル単体に依存せず、**RAG（Retrieval-Augmented Generation）**を組み込むアーキテクチャを検討します。最新の法令データベースを検索・参照させることで、このモデルの「判断力」を最大限に活かしつつ、「知識」の弱点を補完することが可能です。